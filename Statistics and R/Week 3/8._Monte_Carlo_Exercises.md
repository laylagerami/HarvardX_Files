Monte Carlo Exercises
================

``` r
library(rafalib)
```

We have used Monte Carlo simulation throughout this chapter to demonstrate statistical concepts; namely, sampling from the population. We mostly applied this to demonstrate the statistical properties related to inference on differences in averages. Here, we will consider examples of how Monte Carlo simulations are used in practice.

### Monte Carlo Exercise 1

Imagine you are William Sealy Gosset and have just mathematically derived the distribution of the t-statistic when the sample comes from a normal distribution. Unlike Gosset you have access to computers and can use them to check the results.
Let's start by creating an outcome.
Set the seed at 1, use rnorm to generate a random sample of size 5, X1,...,X5 from a standard normal distribution. Compute the t-statistic t = sqrt(5) Xbar/s with s the sample standard deviation. What value do you observe?

``` r
set.seed(1)
sample <- rnorm(n=5)
mean <- mean(sample)
sd <- sd(sample)
t <- sqrt(5)*(mean/sd)
t
```

    ## [1] 0.3007746

### Monte Carlo Exercise 2

You have just performed a Monte Carlo simulation using rnorm , a random number generator for normally distributed data. Gosset's mathematical calculation tells us that the t-statistic defined in the previous exercises, a random variable, follows a t-distribution with N-1 degrees of freedom. Monte Carlo simulations can be used to check the theory: we generate many outcomes and compare them to the theoretical result. Set the seed to 1, generate B=1000 t-statistics as done in exercise 1. What proportion is larger than 2?

``` r
B <- 1000
tstatgen <- function(n, mean=0, sd=1) {
  sample <- rnorm(n,mean,sd)
  mean <- mean(sample)
  sd <- sd(sample)
  tstat <- sqrt(5)*(mean/sd)
  return(tstat)
}
tstats <- replicate(B,tstatgen(5))
mean(tstats > 2)
```

    ## [1] 0.068

### Monte Carlo Exercise 3

The answer to exercise 2 is very similar to the theoretical prediction: 1-pt(2,df=4). We can check several such quantiles using the qqplot function.
To obtain quantiles for the t-distribution we can generate percentiles from just above 0 to just below 1: B=100; ps = seq(1/(B+1), 1-1/(B+1),len=B) and compute the quantiles with qt(ps,df=4). Now we can use qqplot to compare these theoretical quantiles to those obtained in the Monte Carlo simulation. Use Monte Carlo simulation developed for exercise 2 to corroborate that the t-statistic t = sqrt(n) \* xbar/s follows a t-distribution for several values of N. The approximation is spot on for all sample sizes.

``` r
mypar(3,2)

tstatgen <- function(n, mean=0, sd=1) {
  sample <- rnorm(n,mean,sd)
  mean <- mean(sample)
  sd <- sd(sample)
  tstat <- sqrt(n)*(mean/sd)
  return(tstat)
}

B <- 1000
ps <- seq(1/(B+1),1-1/(B+1),len=B)

for(samplesize in c(seq(5,30,5))){
  tstats <- replicate(B,tstatgen(samplesize))
qqplot(qt(ps,df=samplesize-1),qt(tstats,df=samplesize-1),
  main=paste("n=",samplesize,sep=""),
  ylim=c(-6,6),
  xlim=c(-6,6),
  xlab="Theoretical",ylab="Observed")
abline(0,1)
}
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-4-1.png)

### Monte Carlo Exercise 4

Use Monte Carlo simulation to corroborate that the t-statistic comparing two means and obtained with normally distributed (mean 0 and sd) data follows a t-distribution. In this case we will use the t.test function with var.equal=TRUE. With this argument the degrees of freedom will be df=2\*N-2 with N the sample size. For which sample sizes does the approximation best work?
The approximations are spot on for all sample sizes.

``` r
mypar(3,2)

B <- 1000
ps <- seq(1/(B+1),1-1/(B+1),len=B)

for(n in c(seq(5,30,5))){
  tstats <- replicate(B,t.test(rnorm(n=n),rnorm(n=n),var.equal = TRUE)$statistic)
qqplot(qt(ps,df=2*n-2),qt(tstats,df=2*n-2),
  main=paste("n=",n,sep=""),
  ylim=c(-6,6),
  xlim=c(-6,6),
  xlab="Theoretical",ylab="Observed")
abline(0,1)
}
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-5-1.png)

### Monte Carlo Exercise 5

Is the following statement true or false? If instead of generating the sample with X=rnorm(15) we generate it with binary data (either positive or negative 1 with probability 0.5) X =sample(c(-1,1), 15, replace=TRUE) then the t-statistic:
tstat &lt;- sqrt(15)\*mean(X) / sd(X)
is approximated by a t-distribution with 14 degrees of freedom.
FALSE. The population data is not normal thus the theory does not apply. We check with a Monte Carlo simulation. The qqplot shows a large tail. Note that there is a small but positive chance that all the X are the same.In this case the denominator is 0 and the t-statistics is not defined.

``` r
mypar()
n <- 15
B <- 10000
tstats <- replicate(B,{
  X <- sample(c(-1,1),n,replace=TRUE)
  sqrt(n)*mean(X)/sd(X)
})
hist(tstats)
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-6-1.png)

``` r
ps <- seq(1/(B+1),1-1/(B+1),len=B)
qqplot(qt(ps,df=n-1),tstats,xlab="Theoretical",ylab="Observed")
abline(0,1)
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-6-2.png)

### Monte Carlo Exercise 6

Is the following statement true or false ? If instead of generating the sample with X=rnorm(N) with N=1000, we generate the data with binary data X= sample(c(-1,1), N, replace=TRUE), then the t-statistic sqrt(N)\*mean(X)/sd(X) is approximated by a t-distribution with 999 degrees of freedom.
With N=1000, CLT kicks in and the t-statistic is approximated with normal 0,1. Furthermore, t-distribution with df=999 and normal are practically the same.

``` r
mypar()
N <- 1000
B <- 10000
tstats <- replicate(B,{
  X <- sample(c(-1,1),N,replace=TRUE)
  sqrt(N)*mean(X)/sd(X)
})
hist(tstats)
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-7-1.png)

``` r
qqnorm(tstats)
abline(0,1)
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-7-2.png)

### Monte Carlo Exercise 7

We can derive approximation of the distribution of the sample average or the t-statistic theoretically. However, suppose we are interested in the distribution of a statistic for which a theoretical approximation is not immediately obvious.

Consider the sample median as an example. Use a Monte Carlo to determine which of the following best approximates the median of a sample taken from normally distributed population with mean 0 and standard deviation 1.

The sample median is approximately normal with mean 0 and SD larger than 1/sqrt(n)

``` r
B <- 1000
tstatgen <- function(n, mean=0, sd=1) {
  sample <- rnorm(n,mean,sd)
  med <- median(sample)
  return(med)
}
mypar(3,2)
for(n in c(seq(5,30,5))){
meds <- replicate(B,tstatgen(n))
title <- paste("n=",n,", mean=",round( mean(meds), 2) , ", sd*sqrt(n)=", round( sd(meds)*sqrt(n),2) )
hist(meds,main=paste("n=",n))
qqnorm(meds,main=title)
qqline(meds)
}
```

![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-8-1.png)![](8._Monte_Carlo_Exercises_files/figure-markdown_github/unnamed-chunk-8-2.png)
